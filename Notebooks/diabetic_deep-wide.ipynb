{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning step by step:\n",
    "   1. Business & Data Understanding\n",
    "   2. Data Cleaning & Analysis\n",
    "   3. Data Modeling\n",
    "   4. Model Evaluation\n",
    "   5. Model Deployment & Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'defun_with_attributes' from 'tensorflow.python.eager.function' (C:\\Users\\ejhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2f3b7f5e9570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategoricalCrossentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\function\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdef_function\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefun_with_attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'defun_with_attributes' from 'tensorflow.python.eager.function' (C:\\Users\\ejhas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Style using Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business & Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
    "The objective of this notebook is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. \n",
    "Several constraints were placed on the selection of these instances from a larger database. \n",
    "In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Insulin','BMI','PedigreeFunction','Age','y']\n",
    "df_diabetes = pd.read_csv(\"C:/Users/ejhas/OneDrive/Documents/miracles/JOBS/AI Bootcamp/WEEK6/day1/Dataset/pima-indians-diabetes.csv\", header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Total Rows : ', df_diabetes.shape[0])\n",
    "print('Total Columns/Features : ', df_diabetes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_diabetes.hist(figsize=(9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_diabetes.columns:\n",
    "    sns.displot(df_diabetes[x],kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing or Null Data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Missing value percentage checking\n",
    "missing_percentage = (df_diabetes.isnull().sum() / len(df_diabetes)) * 100\n",
    "\n",
    "# Show the missing percentage\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unexpected Outliers Identified from Histogram\n",
    "There are three features that could probably have outliers, such as Glucose, Blood Pressure, BMI, Insulin, Skin Thickness, Pedigree Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the columns with the value \"0\" by creating a boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the \"y\" column\n",
    "columns_to_check = df_diabetes.columns.difference([\"y\"])\n",
    "\n",
    "# Create a boolean mask for rows where the value is \"0\"\n",
    "mask = (df_diabetes[columns_to_check] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the results to see which columns have the value \"0\" in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the boolean mask to check which columns have at least one \"0\" value\n",
    "columns_with_zeros = mask.any()\n",
    "\n",
    "# List the column names with \"0\" values\n",
    "columns_with_zeros = columns_with_zeros[columns_with_zeros].index\n",
    "\n",
    "print(\"Columns with '0' values:\")\n",
    "print(columns_with_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts the number of zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the 'y' column from the selection\n",
    "numeric_columns = df_diabetes.select_dtypes(include=['number']).drop(columns=['y'])\n",
    "\n",
    "# Count the number of zeros in each selected column\n",
    "zero_counts = numeric_columns.eq(0).sum()\n",
    "\n",
    "# Print the columns with zero counts\n",
    "print(\"Columns with zero values and their counts (excluding 'y'):\")\n",
    "print(zero_counts[zero_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='y', data=df_diabetes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_diabetes['y'].value_counts().plot(kind='pie')\n",
    "plt.pie(df_diabetes['y'].value_counts().tolist(), labels=['0', '1'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title(\"Outcomes\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "corr = df_diabetes.corr()\n",
    "sns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n",
    "            ax=ax,\n",
    "            mask=np.triu(corr, k=0),\n",
    "            cmap='viridis',\n",
    "            vmax=1.0, \n",
    "            vmin=-1.0, \n",
    "            linewidths=1.0,\n",
    "            annot=True,\n",
    "            annot_kws={'fontsize': 20},\n",
    "            square=True,\n",
    "            fmt='.3f')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes.corr()['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diabetes Percentage by Age Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Age ranges\n",
    "age_bins = [20, 30, 40, 50, 60, 70, 80]  # Adjust the age ranges as needed\n",
    "age_labels = ['20-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "\n",
    "#Use the pd.cut function to categorize ages into age ranges:\n",
    "df_diabetes['AgeRange'] = pd.cut(df_diabetes['Age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "\n",
    "#Group the data by age range and calculate the percentage of diabetes cases (Diabetes=1):\n",
    "age_diabetes = df_diabetes.groupby('AgeRange')['y'].mean() * 100\n",
    "\n",
    "#Plot the data:\n",
    "plt.bar(age_diabetes.index, age_diabetes)\n",
    "plt.xlabel(\"Age Range\")\n",
    "plt.ylabel(\"Percentage with Diabetes\")\n",
    "plt.title(\"Diabetes Percentage by Age Range\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check BMI distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = 21\n",
    "upper_limit = 80\n",
    "#Filter the DataFrame to select only the rows within your specified range:\n",
    "\n",
    "filtered_df = df_diabetes[(df_diabetes['BMI'] >= lower_limit) & (df_diabetes['BMI'] <= upper_limit)]\n",
    "\n",
    "plt.hist(filtered_df['BMI'], bins=50, edgecolor='k')  # You can adjust the number of bins.\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Histogram of BMI Values in Range {lower_limit}-{upper_limit}')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BMI vs. Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BMI ranges\n",
    "bmi_ranges = [0, 18.5, 24.9, 29.9, 34.9, 100]\n",
    "bmi_labels = ['Underweight', 'Normal', 'Overweight', 'Obese Class I', 'Obese Class II+']\n",
    "\n",
    "#Use the pd.cut function to categorize ages into age ranges:\n",
    "df_diabetes['BMIRange'] = pd.cut(df_diabetes['BMI'], bins=bmi_ranges, labels=bmi_labels, include_lowest=True)\n",
    "\n",
    "#Group the data by age range and calculate the percentage of diabetes cases (Diabetes=1):\n",
    "bmi_diabetes = df_diabetes.groupby('BMIRange')['y'].mean() * 100\n",
    "\n",
    "#Plot the data:\n",
    "plt.bar(bmi_diabetes.index, bmi_diabetes)\n",
    "plt.xlabel(\"BMI Range\")\n",
    "plt.ylabel(\"Percentage with Diabetes\")\n",
    "plt.title(\"Diabetes Percentage by BMI Range\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Glucose vs Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two separate data series for diabetic and non-diabetic patients:\n",
    "glucose_diabetic = df_diabetes[df_diabetes['y'] == 1]['Glucose']\n",
    "\n",
    "glucose_non_diabetic = df_diabetes[df_diabetes['y'] == 0]['Glucose']\n",
    "# Define the bins (ranges) for the histogram\n",
    "bins = [50, 70, 100, 125, 150, 200, 250]\n",
    "\n",
    "# Plot histogram for diabetic patients\n",
    "plt.hist(glucose_diabetic, bins=bins, alpha=0.5, label='Diabetic', color='red')\n",
    "\n",
    "# Plot histogram for non-diabetic patients\n",
    "plt.hist(glucose_non_diabetic, bins=bins, alpha=0.5, label='Non-Diabetic', color='blue')\n",
    "\n",
    "# Labeling and legend\n",
    "plt.xlabel('Glucose Level')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Glucose Distribution by Diabetes Status')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop zero values\n",
    "Since we have 2 columns with too much zero values, we then need to drop:\n",
    "1. SkinThickness    227\n",
    "2. Insulin          374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['SkinThickness', 'Insulin', 'AgeRange', 'BMIRange']\n",
    "df_new = df_diabetes.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating the rest of columns with zero values\n",
    "Glucose has normal distributions, we replace 0 values in those columns by mean value. BMI and Blood Pressure have negative skewed distributions, median will be used to replace them.\n",
    "1. Pregnancies      111\n",
    "2. Glucose            5\n",
    "3. BloodPressure     35\n",
    "4. BMI               11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the skewness for all numerical columns\n",
    "skewness = df_new.skew()\n",
    "\n",
    "# Print the skewness values\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median (excluding zeros)\n",
    "mean = df_new[df_new['Glucose'] != 0]['Glucose'].mean()\n",
    "median_bmi = df_new[df_new['BMI'] != 0]['BMI'].median()\n",
    "median_bp = df_new[df_new['BloodPressure'] != 0]['BloodPressure'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace zeros on Glucose with mean\n",
    "df_new['Glucose'].replace(0, mean, inplace=True)\n",
    "\n",
    "# Replace zeros on BMI with median\n",
    "df_new['BMI'].replace(0, median_bmi, inplace=True)\n",
    "\n",
    "# Replace zeros on BloodPressure with median\n",
    "df_new['BloodPressure'].replace(0, median_bp, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.eq(0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_new.values[:,:6]\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_new.values[:,6:]\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras sequential model\n",
    "model = Sequential()\n",
    "#define the neural network\n",
    "model.add(Dense(20, input_dim=6, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the backpropagation\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a callback\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if(logs.get('val_accuracy')>0.80):\n",
    "            print('\\nReeached 80%, cancel training')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the custom callback\n",
    "callback = CustomCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, \n",
    "          epochs=140, batch_size=7, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe\n",
    "model_hist = pd.DataFrame(model.history.history)\n",
    "model_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#accuracy vs. val_accuracy plot \n",
    "plt.figure(figsize=[8,5])\n",
    "plt.plot(model_hist['accuracy'], 'r', label='Training Acc')\n",
    "plt.plot(model_hist['val_accuracy'], 'b', label='Validation Acc')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.title('Accuracy Curves', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model in train dataset\n",
    "_, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(f'Accuracy: {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model in test dateset\n",
    "_, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'Accuracy: {accuracy*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss vs. val_loss plot \n",
    "plt.figure(figsize=[8,5])\n",
    "plt.plot(model_hist['loss'], 'r', label='Training Loss')\n",
    "plt.plot(model_hist['val_loss'], 'b', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.title('Loss Curves', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
